{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUOXU48yodSDN0Ed6Xs/rm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulmu99/Playdata/blob/main/Deep_learning/5_Learn_about_the_optimization_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing the model parameters"
      ],
      "metadata": {
        "id": "lUfNOzzb6u4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6iMHpoy6bA6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download =True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdgLM_oH7mH3",
        "outputId": "63d34b88-a000-419f-a085-337360008d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15096004.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 272110.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5010492.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 28636972.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "r7p57vV472Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size = 64 )\n",
        "test_dataloader =  DataLoader(test_data, batch_size =64)"
      ],
      "metadata": {
        "id": "NjM5yexb76xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),\n",
        "        nn.ReLU()\n",
        "       )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "pweIJKjv8PSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "XFNujAfF9Vwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Setting hyperparameters\n",
        "- Epoch\n",
        "- batch_size\n",
        "- learning_rate"
      ],
      "metadata": {
        "id": "C73k4V_W9lCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "v9w675xx9aCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Add an optimization loop\n",
        "- The Train Loop\n",
        "> iterate over the training dataset and try to converge to optimal parameters.   \n",
        "- The Validation/test Loop\n",
        "> iterate over the test dataset to check if model performance is improving."
      ],
      "metadata": {
        "id": "TU2HCwR195h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add a loss function\n",
        "- `nn.MSELoss` (Mean Square Error) used for regression tasks\n",
        "- `nn.NLLLoss` (Negative Log Likelihood) used for classification\n",
        "- `nn.CrossEntropyLoss` combines `nn.LogSoftmax` and `nn.NLLLoss`"
      ],
      "metadata": {
        "id": "vGqDBZAj_pw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the loss fuction\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "6yfOK3Lx94qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization pass"
      ],
      "metadata": {
        "id": "Naae7eH0ADae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "apuhzgwW_9-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation\n",
        "- optimizer.zero_grad()\n",
        "> 역전파 단계를 실행하기 전에 각 파라미터들의 변화도(gradient)를 0으로 재설정\n",
        "\n",
        "- loss.backward()\n",
        "> 역전파 단계: 모델의 학습을 가능한 모든 매개변수에 대해 손실의 변화도 계산\n",
        "\n",
        "- optimizer.step()\n",
        "> 변화도를 계산한 뒤에 `optimizer.step()`을 호춯하여 역전파 단계에서 수집된 변화도로 매개변수 조정"
      ],
      "metadata": {
        "id": "58qJcMYNApIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.Full implementation"
      ],
      "metadata": {
        "id": "tuFxacPhCxBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader,model,loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch ,(X,y) in enumerate(dataloader):   #train data에서 64개씩 나눠서 학습\n",
        "    #compute prediction and loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backpropagation \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item() , batch * len(X) \n",
        "      print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
        "    "
      ],
      "metadata": {
        "id": "af-bRpZjAggR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):    #test는 optimizer  X\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()    #batch별 loss\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  test_loss /= size   #오답율\n",
        "  correct /= size     #정답율\n",
        "  print(f'Test Error\" \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n')"
      ],
      "metadata": {
        "id": "Y92NX3KLEajm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)\n",
        "\n",
        "epoch = 10\n",
        "for t in range(epoch):\n",
        "  print(f'Epoch {t+1}\\n-------------------')\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzVz20iLGE4A",
        "outputId": "29dde4f7-6956-4b64-99dc-70e1261854e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------\n",
            "loss: 2.296743  [    0/60000]\n",
            "loss: 2.287503  [ 6400/60000]\n",
            "loss: 2.279446  [12800/60000]\n",
            "loss: 2.290223  [19200/60000]\n",
            "loss: 2.257495  [25600/60000]\n",
            "loss: 2.249572  [32000/60000]\n",
            "loss: 2.243126  [38400/60000]\n",
            "loss: 2.225015  [44800/60000]\n",
            "loss: 2.226043  [51200/60000]\n",
            "loss: 2.223431  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 37.2%, Avg loss: 0.034851\n",
            "\n",
            "Epoch 2\n",
            "-------------------\n",
            "loss: 2.188293  [    0/60000]\n",
            "loss: 2.196789  [ 6400/60000]\n",
            "loss: 2.185410  [12800/60000]\n",
            "loss: 2.239280  [19200/60000]\n",
            "loss: 2.144704  [25600/60000]\n",
            "loss: 2.135642  [32000/60000]\n",
            "loss: 2.132953  [38400/60000]\n",
            "loss: 2.091267  [44800/60000]\n",
            "loss: 2.113239  [51200/60000]\n",
            "loss: 2.115427  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 38.4%, Avg loss: 0.033107\n",
            "\n",
            "Epoch 3\n",
            "-------------------\n",
            "loss: 2.042401  [    0/60000]\n",
            "loss: 2.065198  [ 6400/60000]\n",
            "loss: 2.043508  [12800/60000]\n",
            "loss: 2.159828  [19200/60000]\n",
            "loss: 1.979615  [25600/60000]\n",
            "loss: 1.975802  [32000/60000]\n",
            "loss: 1.976966  [38400/60000]\n",
            "loss: 1.910223  [44800/60000]\n",
            "loss: 1.960962  [51200/60000]\n",
            "loss: 1.970767  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 41.6%, Avg loss: 0.030886\n",
            "\n",
            "Epoch 4\n",
            "-------------------\n",
            "loss: 1.853450  [    0/60000]\n",
            "loss: 1.905164  [ 6400/60000]\n",
            "loss: 1.878735  [12800/60000]\n",
            "loss: 2.061301  [19200/60000]\n",
            "loss: 1.812343  [25600/60000]\n",
            "loss: 1.816654  [32000/60000]\n",
            "loss: 1.811145  [38400/60000]\n",
            "loss: 1.737235  [44800/60000]\n",
            "loss: 1.803125  [51200/60000]\n",
            "loss: 1.828820  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 44.0%, Avg loss: 0.028806\n",
            "\n",
            "Epoch 5\n",
            "-------------------\n",
            "loss: 1.671525  [    0/60000]\n",
            "loss: 1.765457  [ 6400/60000]\n",
            "loss: 1.735541  [12800/60000]\n",
            "loss: 1.965041  [19200/60000]\n",
            "loss: 1.678862  [25600/60000]\n",
            "loss: 1.691363  [32000/60000]\n",
            "loss: 1.670280  [38400/60000]\n",
            "loss: 1.601753  [44800/60000]\n",
            "loss: 1.671258  [51200/60000]\n",
            "loss: 1.719191  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 44.7%, Avg loss: 0.027121\n",
            "\n",
            "Epoch 6\n",
            "-------------------\n",
            "loss: 1.525408  [    0/60000]\n",
            "loss: 1.653775  [ 6400/60000]\n",
            "loss: 1.620656  [12800/60000]\n",
            "loss: 1.887174  [19200/60000]\n",
            "loss: 1.577097  [25600/60000]\n",
            "loss: 1.598001  [32000/60000]\n",
            "loss: 1.567022  [38400/60000]\n",
            "loss: 1.503572  [44800/60000]\n",
            "loss: 1.577003  [51200/60000]\n",
            "loss: 1.642011  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 45.3%, Avg loss: 0.025829\n",
            "\n",
            "Epoch 7\n",
            "-------------------\n",
            "loss: 1.421426  [    0/60000]\n",
            "loss: 1.565647  [ 6400/60000]\n",
            "loss: 1.531028  [12800/60000]\n",
            "loss: 1.827995  [19200/60000]\n",
            "loss: 1.500559  [25600/60000]\n",
            "loss: 1.531349  [32000/60000]\n",
            "loss: 1.494731  [38400/60000]\n",
            "loss: 1.433669  [44800/60000]\n",
            "loss: 1.512135  [51200/60000]\n",
            "loss: 1.587998  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 46.0%, Avg loss: 0.024862\n",
            "\n",
            "Epoch 8\n",
            "-------------------\n",
            "loss: 1.347987  [    0/60000]\n",
            "loss: 1.498723  [ 6400/60000]\n",
            "loss: 1.461416  [12800/60000]\n",
            "loss: 1.783005  [19200/60000]\n",
            "loss: 1.445644  [25600/60000]\n",
            "loss: 1.483059  [32000/60000]\n",
            "loss: 1.443565  [38400/60000]\n",
            "loss: 1.381997  [44800/60000]\n",
            "loss: 1.464415  [51200/60000]\n",
            "loss: 1.547729  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 46.5%, Avg loss: 0.024113\n",
            "\n",
            "Epoch 9\n",
            "-------------------\n",
            "loss: 1.293934  [    0/60000]\n",
            "loss: 1.446906  [ 6400/60000]\n",
            "loss: 1.405017  [12800/60000]\n",
            "loss: 1.748508  [19200/60000]\n",
            "loss: 1.404392  [25600/60000]\n",
            "loss: 1.445840  [32000/60000]\n",
            "loss: 1.405436  [38400/60000]\n",
            "loss: 1.341724  [44800/60000]\n",
            "loss: 1.425871  [51200/60000]\n",
            "loss: 1.516182  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 47.3%, Avg loss: 0.023502\n",
            "\n",
            "Epoch 10\n",
            "-------------------\n",
            "loss: 1.249408  [    0/60000]\n",
            "loss: 1.403565  [ 6400/60000]\n",
            "loss: 1.358081  [12800/60000]\n",
            "loss: 1.720742  [19200/60000]\n",
            "loss: 1.372429  [25600/60000]\n",
            "loss: 1.415249  [32000/60000]\n",
            "loss: 1.375039  [38400/60000]\n",
            "loss: 1.307685  [44800/60000]\n",
            "loss: 1.393691  [51200/60000]\n",
            "loss: 1.490208  [57600/60000]\n",
            "Test Error\" \n",
            " Accuracy: 48.2%, Avg loss: 0.022990\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Saving Models"
      ],
      "metadata": {
        "id": "_kxBonMoJ5iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'data/model.pth' )  #모델 저장\n",
        "\n",
        "print('Saved PyTorch Model State to model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqCL2K24HHCr",
        "outputId": "f06ad3f9-e107-4060-ed2e-b91176ae14b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.Loading Models"
      ],
      "metadata": {
        "id": "7iXC8dURKR6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load('data/model.pth')) # 모델 불러오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbFW2V0AKQdY",
        "outputId": "f978e4bd-7df4-4c8b-917b-1b29fbe4e0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Prediction"
      ],
      "metadata": {
        "id": "m_nf3S5XKpzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()  #  모델을 예측 모드로 변경\n",
        "X, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():  #모델 예측\n",
        "  pred = model(X)\n",
        "  predicted, actual  = classes[pred[0].argmax(0)], classes[y]\n",
        "  print(f'Predicted: \"{predicted}\"\" Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSnEho8zKijb",
        "outputId": "8e86e1de-6c8e-4e15-e3e6-9079ef19e98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\"\" Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7KR_gqd2M26u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}